
## 1.0 บทนำ: เหตุใดการเตรียมข้อมูลจึงเป็นหัวใจของ Data Visualization ที่มีคุณภาพ

ก่อนที่จะสามารถสร้างงาน **การแสดงผลข้อมูล (Data Visualization)** ที่มีความหมาย น่าเชื่อถือ และสื่อสารข้อมูลเชิงลึกได้อย่างมีประสิทธิภาพ จำเป็นต้องผ่านขั้นตอนที่สำคัญที่สุดขั้นตอนหนึ่ง นั่นคือ **การเตรียมข้อมูล (Data Preparation)** คุณภาพของ Visualization ไม่ได้ขึ้นอยู่กับความสวยงามของกราฟเพียงอย่างเดียว แต่ขึ้นอยู่โดยตรงกับความถูกต้อง สมบูรณ์ และความสอดคล้องของข้อมูลตั้งต้น

ในเชิงทฤษฎี Data Visualization คือกระบวนการ *ถ่ายทอดข้อมูล (data mapping)* ไปสู่การเข้ารหัสเชิงภาพ (visual encodings) เช่น ตำแหน่ง สี หรือขนาด หากข้อมูลดิบมีปัญหา เช่น ค่าที่ขาดหาย (missing values) ค่าผิดปกติ (outliers) หรือชนิดข้อมูลไม่ถูกต้อง การถ่ายทอดดังกล่าวจะบิดเบือนความจริง และนำไปสู่การตีความที่คลาดเคลื่อน

ดังนั้น การเตรียมข้อมูลจึงไม่ใช่เพียงขั้นตอนทางเทคนิค แต่เป็น **รากฐานเชิงระเบียบวิธี (methodological foundation)** ของการวิเคราะห์ข้อมูลและการสื่อสารเชิงภาพที่ถูกต้อง

### วัตถุประสงค์การเรียนรู้

เมื่อจบ Module นี้ ผู้เรียนจะสามารถ:

- **อธิบายกระบวนการเตรียมข้อมูลอย่างเป็นระบบ** ก่อนนำไปสร้าง Visualization  
- **ตระหนักและประเมินปัญหาคุณภาพข้อมูล** เช่น Missing Values, Outliers และรูปแบบข้อมูลที่ไม่เหมาะสม  
- **ประยุกต์ใช้ Python และ pandas** เพื่อปรับปรุงคุณภาพข้อมูลสำหรับงาน Visualization  

---

## 2.0 กระบวนการเตรียมข้อมูล: จากข้อมูลดิบสู่ข้อมูลพร้อมใช้

การเตรียมข้อมูลมักดำเนินตามลำดับขั้นที่เป็นระบบ ได้แก่ การสำรวจ (inspection) การวินิจฉัยปัญหา (diagnosis) และการปรับปรุงข้อมูล (transformation) ซึ่งสอดคล้องกับแนวปฏิบัติมาตรฐานในงาน Data Science

ใน Module นี้ จะใช้ชุดข้อมูลตัวอย่าง `student-raw.csv` เพื่ออธิบายกระบวนการทั้งหมด

---

## 2.1 การเริ่มต้น: การนำเข้าและสำรวจข้อมูลเบื้องต้น

เริ่มจากการโหลดข้อมูลเข้าสู่สภาพแวดล้อมการทำงานด้วย Python

```python
import pandas as pd

# Load raw dataset
df = pd.read_csv("student-raw.csv")
````

ขั้นตอนถัดมาคือ **การสำรวจข้อมูลเชิงสำรวจ (Exploratory Inspection)** เพื่อทำความเข้าใจโครงสร้างและคุณภาพของข้อมูลก่อนลงมือปรับปรุง

### 2.1.1 การตรวจสอบข้อมูลตัวอย่าง

```python
# แสดงข้อมูล 5 แถวแรก
df.head()
```

คำสั่งนี้ช่วยให้เห็น:

* โครงสร้างของคอลัมน์
* รูปแบบของข้อมูล
* ความผิดปกติที่อาจสังเกตได้ทันที

### 2.1.2 การตรวจสอบขนาดของชุดข้อมูล

```python
# ขนาดของ dataset (จำนวนแถว, จำนวนคอลัมน์)
df.shape
```

ข้อมูลนี้ช่วยให้ประเมินสัดส่วนของปัญหา เช่น จำนวน missing values เมื่อเทียบกับข้อมูลทั้งหมด

### 2.1.3 การสรุปเชิงสถิติเพื่อวินิจฉัยปัญหา

```python
# สรุปข้อมูลเชิงสถิติ
df.describe(include="all")
```

ในเชิงทฤษฎี การสรุปข้อมูลนี้ทำหน้าที่เป็น **เครื่องมือยืนยันความสมเหตุสมผลของข้อมูล (data validation)** โดยประเด็นสำคัญที่ควรพิจารณา ได้แก่:

* **Missing Values**: ค่า `count` ที่น้อยกว่าจำนวนแถวทั้งหมด
* **Outliers ที่อาจเกิดขึ้น**: ค่า `min` หรือ `max` ที่ไม่สมเหตุสมผล เช่น GPA < 0 หรือ GPA > 4.0

---

## 2.2 การจัดการปัญหาคุณภาพข้อมูล

เมื่อระบุปัญหาแล้ว ขั้นตอนต่อไปคือการจัดการคุณภาพข้อมูลอย่างมีเหตุผล โดยใน Module นี้จะเน้น 3 ประเด็นหลัก ได้แก่ Missing Values, Outliers และชนิดข้อมูล

---

## 2.2.1 การจัดการข้อมูลที่ขาดหาย (Missing Values)

ข้อมูลที่ขาดหายเป็นปรากฏการณ์ปกติในข้อมูลจริง แต่ต้องได้รับการจัดการอย่างรอบคอบ

### แนวคิดเชิงทฤษฎีที่ใช้บ่อย

1. **การลบข้อมูล (Dropping)**
   เหมาะเมื่อข้อมูลที่หายมีจำนวนน้อยและไม่กระทบภาพรวม

2. **การแทนค่า (Imputation)**
   เช่น การใช้ค่าเฉลี่ยหรือค่ามัธยฐาน เพื่อรักษาจำนวนข้อมูล

3. **การคงไว้เพื่อการวิเคราะห์เพิ่มเติม**
   เมื่อรูปแบบของการหายไปมีนัยสำคัญทางการวิเคราะห์

### การตรวจสอบ Missing Values

```python
# ตรวจสอบจำนวน missing values ในแต่ละคอลัมน์
df.isna().sum()
```

### ตัวอย่าง: การแทนค่า GPA ด้วยค่าเฉลี่ย

```python
# แทนค่า GPA ที่ขาดหายด้วยค่าเฉลี่ย
df["gpa"] = df["gpa"].fillna(df["gpa"].mean())
```

แม้ว่าวิธีนี้จะช่วยรักษาจำนวนข้อมูล แต่ก็ลดความแปรปรวนของข้อมูลลงเล็กน้อย ซึ่งอาจส่งผลต่อการตีความ Visualization

---

## 2.2.2 การพิจารณาข้อมูลสุดโต่ง (Outliers)

Outliers คือค่าที่แตกต่างจากกลุ่มข้อมูลส่วนใหญ่อย่างชัดเจน ซึ่งอาจเกิดจากความผิดพลาดหรือเหตุการณ์ที่เกิดขึ้นได้ยากแต่เป็นจริง

```python
# ตรวจสอบค่าสถิติเบื้องต้นของ GPA
df["gpa"].describe()
```

**หลักการสำคัญ:**
Outliers ไม่ควรถูกลบโดยอัตโนมัติ แต่ควรพิจารณาร่วมกับบริบทของข้อมูลและวัตถุประสงค์ของการวิเคราะห์

---

## 2.2.3 การปรับชนิดและรูปแบบข้อมูล (Data Formatting)

ชนิดข้อมูลที่ถูกต้องเป็นเงื่อนไขพื้นฐานของ Visualization โดยเฉพาะข้อมูลเชิงเวลา

```python
# ตรวจสอบชนิดข้อมูล
df.dtypes
```

### ตัวอย่าง: การแปลงข้อมูลวันที่

```python
# แปลง enrollment_date เป็น datetime
df["enrollment_date"] = pd.to_datetime(df["enrollment_date"])
```

การแปลงนี้ทำให้สามารถสร้างกราฟเชิงเวลา การจัดเรียง และการวิเคราะห์แนวโน้มได้อย่างถูกต้อง

---

## 3.0 ผลลัพธ์เชิงประจักษ์: การเปรียบเทียบข้อมูลก่อนและหลังการเตรียม

การเปรียบเทียบข้อมูลก่อนและหลังการทำความสะอาดเป็นขั้นตอนเชิงกลยุทธ์ที่ช่วยยืนยันผลลัพธ์ของการเตรียมข้อมูล

```python
# ข้อมูลดิบ
df_raw = pd.read_csv("student-raw.csv")

# ข้อมูลหลัง clean
df_clean = df.copy()

# เปรียบเทียบค่าสถิติ
df_raw.describe()
df_clean.describe()
```

### การสะท้อนเชิงวิเคราะห์

การเปลี่ยนแปลงเพียงเล็กน้อยในค่าเฉลี่ยหรือค่าสูงสุด อาจนำไปสู่การเล่าเรื่อง (data narrative) ที่แตกต่างอย่างมีนัยสำคัญใน Visualization

ประเด็นที่ควรถาม ได้แก่:

* Visualization เปลี่ยนไปอย่างไรหลังการเตรียมข้อมูล
* Insight หรือข้อสรุปใดอาจเปลี่ยนแปลงไปจากเดิม

---

## 4.0 บทสรุปและแนวทางการเรียนรู้เพิ่มเติม

การเตรียมข้อมูลเป็นขั้นตอนพื้นฐานที่กำหนดคุณภาพของ Data Visualization ทั้งหมด Visualization ที่ดีไม่ได้เริ่มจากกราฟที่ซับซ้อน แต่เริ่มจากข้อมูลที่ผ่านการตรวจสอบและปรับปรุงอย่างรอบคอบ

### ประเด็นสำคัญที่ได้เรียนรู้

1. การเตรียมข้อมูลกำหนดความน่าเชื่อถือของ Visualization
2. การสำรวจข้อมูลก่อนปรับปรุงเป็นขั้นตอนที่ขาดไม่ได้
3. การจัดการ Missing Values และ Outliers ต้องอาศัยทั้งเทคนิคและบริบทของข้อมูล

> **Visualization ที่ดี เริ่มต้นจากข้อมูลที่ดี**

---

## กิจกรรมฝึกฝนเพิ่มเติม (Self-Study)

* สร้าง Boxplot เพื่อเปรียบเทียบการกระจายของ GPA ก่อนและหลังการเตรียมข้อมูล
* ทดลองวิธีจัดการ Missing Values แบบอื่น (median, dropna) และเปรียบเทียบผล
* วิเคราะห์ผลกระทบของแต่ละวิธีต่อกราฟและ Insight ที่ได้

